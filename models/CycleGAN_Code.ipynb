{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Image-to-image classification network \n",
    "CycleGAN Resources used: \n",
    "https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "https://keras.io/examples/generative/cyclegan/\n",
    "https://machinelearningmastery.com/cyclegan-tutorial-with-keras/\n",
    "\n",
    "SVM Resources used:  \n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## import tensorflow and alocate GPU memory growth\n",
    "'''\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## CycleGAN libraries needed\n",
    "'''\n",
    "import numpy as np\n",
    "from random import random\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import vstack\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from numpy import savez_compressed\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Libraries for the SVM \n",
    "\"\"\"\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the training and test set from a tradionally trained CNN \n",
    "train_csv = pd.read_csv('/CNN_trainset.csv')\n",
    "test_csv = pd.read_csv('/CNN_valset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Split the training and test set based on malignant and benign images. \n",
    "train_A = train_csv[train_csv.target==1]\n",
    "test_A = test_csv[test_csv.target==1]\n",
    "train_B = train_csv[train_csv.target==0]\n",
    "test_B = test_csv[test_csv.target==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sample 453 benign images so that there are equal classes of benign and malignant images\n",
    "#train_B = train_B.sample(n=453, random_state = 316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## load all images in a directory into memory\n",
    "def load_images(path, image_list = None, filetype = None, size=(256,256)):\n",
    "    data_list = list()\n",
    "    # enumerate filenames in directory, assume all are images\n",
    "    if image_list = None: \n",
    "        image_list = listdir(path)\n",
    "    for filename in image_list:\n",
    "        # load and resize the image\n",
    "        if filetype == None:\n",
    "            pixels = load_img(path + filename , target_size=size)\n",
    "        else: \n",
    "            pixels = load_img(path + filename + filetype, target_size=size)\n",
    "        # convert to numpy array\n",
    "        pixels = img_to_array(pixels)\n",
    "        # store\n",
    "        data_list.append(pixels)\n",
    "    return asarray(data_list)\n",
    "\n",
    "\n",
    "## dataset path\n",
    "path = ''\n",
    "\n",
    "# load dataset A \n",
    "dataA1 = load_images(path, train_A['image_dir'].to_numpy())\n",
    "dataA2 = load_images(path, test_A['image_dir'].to_numpy())\n",
    "# load dataset B\n",
    "dataB1 = load_images(path, train_B['image_dir'].to_numpy())\n",
    "dataB2 = load_images(path, test_B['image_dir'].to_numpy())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load saved CNN/CycleGAN Dataset data\"\"\"\n",
    "dataset = np.load('mal2ben_CNN.npz')\n",
    "dataA1, dataA2, dataB1, dataB2,  = dataset['arr_0'], dataset['arr_1'], dataset['arr_2'], dataset['arr_3']\n",
    "print('Loaded: ', dataA1.shape, dataA2.shape, dataB1.shape, dataB2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the ground truth value as numpy array. \n",
    "testA_ground_truth = test_A['target'].to_numpy()\n",
    "testB_ground_truth = test_B['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a copy of the CSV dataframe \n",
    "csv_testA = test_A\n",
    "csv_testB = test_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Define the standard image size.\n",
    "orig_img_size = (256, 256)\n",
    "# Size of the random crops to be used during training.\n",
    "input_img_size = (256, 256, 3)\n",
    "# Weights initializer for the layers.\n",
    "kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "# Gamma initializer for instance normalization.\n",
    "gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "buffer_size = 256\n",
    "batch_size = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    # Map values in the range [-1, 1]\n",
    "    return (img / 127.5) - 1.0\n",
    "\n",
    "def preprocess_train_image(img):\n",
    "    # Random flip\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    # Resize to the original size first\n",
    "    img = tf.image.resize(img, [*orig_img_size])\n",
    "    # Random crop to 256X256\n",
    "    img = tf.image.random_crop(img, size=[*input_img_size])\n",
    "    # Normalize the pixel values in the range [-1, 1]\n",
    "    img = normalize_img(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_test_image(img):\n",
    "    # Only resizing and normalization for the test images.\n",
    "    img = tf.image.resize(img, [input_img_size[0], input_img_size[1]])\n",
    "    img = normalize_img(img)\n",
    "#     img = tf.image.rot90(img, k=3)\n",
    "    return img\n",
    "\n",
    "def random_jitter(image):\n",
    "  # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "    image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creation(dataset, preprocess_image, shuffle = True):\n",
    "    tensor_dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    if shuffle == True:\n",
    "        mapped_dataset = (\n",
    "            tensor_dataset.map(preprocess_test_image, num_parallel_calls=autotune)\n",
    "                .cache()\n",
    "                .shuffle(buffer_size)\n",
    "                .batch(batch_size)\n",
    "            )\n",
    "    else: \n",
    "        mapped_dataset = (\n",
    "            tensor_dataset.map(preprocess_test_image, num_parallel_calls=autotune)\n",
    "                .cache()\n",
    "                #.shuffle(buffer_size)\n",
    "                .batch(batch_size)\n",
    "            )\n",
    "    return mapped_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Create `Dataset` objects\n",
    "\"\"\"\n",
    "\n",
    "trainA_data = dataset_creation(dataA1, preprocess_train_image)\n",
    "trainB_data = dataset_creation(dataB1, preprocess_train_image)\n",
    "\n",
    "trainA_data2 = dataset_creation(dataA1, preprocess_test_image, False)\n",
    "trainB_data2 = dataset_creation(dataB1, preprocess_test_image, False)\n",
    "\n",
    "testA_data = dataset_creation(dataA2, preprocess_test_image, False)\n",
    "testB_data = dataset_creation(dataB2, preprocess_test_image, False)\n",
    "\n",
    "## Additional Datasets\n",
    "#large_benign_test_data = dataset_creation(benign_test, preprocess_test_image)\n",
    "#mal_2016_test_data = dataset_creation(malignant_2016_images, preprocess_test_image)\n",
    "#mal_2017_test_data = dataset_creation(malignant_2017_images, preprocess_test_image)\n",
    "\n",
    "#hist_ben_test_data = dataset_creation(hist_ben_test, preprocess_test_image)\n",
    "#single_ben_test_data = dataset_creation(single_ben_test, preprocess_test_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an empty array and then calculate the distance between every cycled image and its original image. \n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "def distance_array(cycled, original, Ltype):\n",
    "    dist_array = np.zeros(cycled.shape[0])\n",
    "    if Ltype == 'L2': #Calculate the L2 distance \n",
    "        for i, val in enumerate(cycled):\n",
    "            dist = np.linalg.norm((cycled[i]/.255).ravel() - (original[i]/.255).ravel(), ord =2)\n",
    "            dist_array[i] = dist\n",
    "    elif Ltype == 'L1': #Calculate the L1 distance \n",
    "        for i, val in enumerate(cycled):\n",
    "            dist = np.linalg.norm((cycled[i]/.255).ravel() - (original[i]/.255).ravel(), ord =1)\n",
    "            dist_array[i] = dist\n",
    "    elif Ltype == 'SSIM':#Calculate SSIM index \n",
    "        for i, val in enumerate(cycled):\n",
    "            dist = ssim(original[i]/255., cycled[i]/255., multichannel = True)\n",
    "            dist_array[i] = dist\n",
    "    return dist_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Building blocks used in the CycleGAN generators and discriminators\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ReflectionPadding2D(layers.Layer):\n",
    "    \"\"\"Implements Reflection Padding as a layer.\n",
    "    Args:\n",
    "        padding(tuple): Amount of padding for the\n",
    "        spatial dimensions.\n",
    "    Returns:\n",
    "        A padded tensor with the same type as the input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        padding_width, padding_height = self.padding\n",
    "        padding_tensor = [\n",
    "            [0, 0],\n",
    "            [padding_height, padding_height],\n",
    "            [padding_width, padding_width],\n",
    "            [0, 0],\n",
    "        ]\n",
    "        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n",
    "\n",
    "\n",
    "def residual_block(\n",
    "    x,\n",
    "    activation,\n",
    "    kernel_initializer=kernel_init,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding=\"valid\",\n",
    "    gamma_initializer=gamma_init,\n",
    "    use_bias=False,\n",
    "):\n",
    "    dim = x.shape[-1]\n",
    "    input_tensor = x\n",
    "\n",
    "    x = ReflectionPadding2D()(input_tensor)\n",
    "    x = layers.Conv2D(\n",
    "        dim,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x = InstanceNormalization(axis=-1)(x)\n",
    "    x = activation(x)\n",
    "    #Dropout\n",
    "    x = layers.Dropout(.5, seed = 316)(x)\n",
    "\n",
    "    x = ReflectionPadding2D()(x)\n",
    "    x = layers.Conv2D(\n",
    "        dim,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x = InstanceNormalization(axis=-1)(x)    \n",
    "    x = layers.add([input_tensor, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def downsample(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_initializer=kernel_init,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(2, 2),\n",
    "    padding=\"same\",\n",
    "    gamma_initializer=gamma_init,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x =  InstanceNormalization(axis=-1)(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def upsample(\n",
    "    x,\n",
    "    filters,\n",
    "    activation,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(2, 2),\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=kernel_init,\n",
    "    gamma_initializer=gamma_init,\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = layers.Conv2DTranspose(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        use_bias=use_bias,\n",
    "    )(x)\n",
    "    x =  InstanceNormalization(axis=-1)(x)\n",
    "    if activation:\n",
    "        x = activation(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Build the generators\n",
    "The generator consists of downsampling blocks: nine residual blocks\n",
    "and upsampling blocks. The structure of the generator is the following:\n",
    "```\n",
    "c7s1-64 ==> Conv block with `relu` activation, filter size of 7\n",
    "d128 ====|\n",
    "         |-> 2 downsampling blocks\n",
    "d256 ====|\n",
    "R256 ====|\n",
    "R256     |\n",
    "R256     |\n",
    "R256     |\n",
    "R256     |-> 9 residual blocks\n",
    "R256     |\n",
    "R256     |\n",
    "R256     |\n",
    "R256 ====|\n",
    "u128 ====|\n",
    "         |-> 2 upsampling blocks\n",
    "u64  ====|\n",
    "c7s1-3 => Last conv block with `tanh` activation, filter size of 7.\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_resnet_generator(\n",
    "    filters=64,\n",
    "    num_downsampling_blocks=2,\n",
    "    num_residual_blocks=9,\n",
    "    num_upsample_blocks=2,\n",
    "    gamma_initializer=gamma_init,\n",
    "    name=None,\n",
    "):\n",
    "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
    "    x = ReflectionPadding2D(padding=(3, 3))(img_input)\n",
    "    x = layers.Conv2D(filters, (7, 7), kernel_initializer=kernel_init, use_bias=False)(\n",
    "        x\n",
    "    )\n",
    "    \n",
    "    x =  InstanceNormalization(axis=-1)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    # Downsampling\n",
    "    for _ in range(num_downsampling_blocks):\n",
    "        filters *= 2\n",
    "        x = downsample(x, filters=filters, activation=layers.Activation(\"relu\"))\n",
    "\n",
    "    # Residual blocks\n",
    "    for _ in range(num_residual_blocks):\n",
    "        x = residual_block(x, activation=layers.Activation(\"relu\"))\n",
    "\n",
    "    # Upsampling\n",
    "    for _ in range(num_upsample_blocks):\n",
    "        filters //= 2\n",
    "        x = upsample(x, filters, activation=layers.Activation(\"relu\"))\n",
    "\n",
    "    # Final block\n",
    "    x = ReflectionPadding2D(padding=(3, 3))(x)\n",
    "    x = layers.Conv2D(3, (7, 7), padding=\"valid\")(x)\n",
    "    x = layers.Activation(\"tanh\")(x)\n",
    "\n",
    "    model = keras.models.Model(img_input, x, name=name)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Build the discriminators\n",
    "The discriminators implement the following architecture:\n",
    "`C64->C128->C256->C512`\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_discriminator(\n",
    "    filters=64, kernel_initializer=kernel_init, num_downsampling=3, name=None\n",
    "):\n",
    "    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n",
    "    x = layers.Conv2D(\n",
    "        filters,\n",
    "        (4, 4),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=kernel_initializer,\n",
    "    )(img_input)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    num_filters = filters\n",
    "    for num_downsample_block in range(3):\n",
    "        num_filters *= 2\n",
    "        if num_downsample_block < 2:\n",
    "            x = downsample(\n",
    "                x,\n",
    "                filters=num_filters,\n",
    "                activation=layers.LeakyReLU(0.2),\n",
    "                kernel_size=(4, 4),\n",
    "                strides=(2, 2),\n",
    "            )\n",
    "        else:\n",
    "            x = downsample(\n",
    "                x,\n",
    "                filters=num_filters,\n",
    "                activation=layers.LeakyReLU(0.2),\n",
    "                kernel_size=(4, 4),\n",
    "                strides=(1, 1),\n",
    "            )\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        1, (4, 4), strides=(1, 1), padding=\"same\", kernel_initializer=kernel_initializer\n",
    "    )(x)\n",
    "\n",
    "    model = keras.models.Model(inputs=img_input, outputs=x, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Save the CycleGAN model's generators and discriminators\n",
    "\"\"\"\n",
    "def save_model(cycleGan, path):\n",
    "    cycleGan.disc_Y.save(path + '/disc_Y')\n",
    "    cycleGan.disc_X.save(path + '/disc_X')\n",
    "    cycleGan.gen_F.save(path + '/gen_F')\n",
    "    cycleGan.gen_G.save(path + '/gen_G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Create the CycleGAN model\n",
    "\"\"\"\n",
    "\n",
    "class CycleGan(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator_G,\n",
    "        generator_F,\n",
    "        discriminator_X,\n",
    "        discriminator_Y,\n",
    "        lambda_cycle=10.0,\n",
    "        lambda_identity= .5,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.gen_G = generator_G\n",
    "        self.gen_F = generator_F\n",
    "        self.disc_X = discriminator_X\n",
    "        self.disc_Y = discriminator_Y\n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        self.lambda_identity = lambda_identity\n",
    "    def call (self, inputs):\n",
    "        return \n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        gen_G_optimizer,\n",
    "        gen_F_optimizer,\n",
    "        disc_X_optimizer,\n",
    "        disc_Y_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.gen_G_optimizer = gen_G_optimizer\n",
    "        self.gen_F_optimizer = gen_F_optimizer\n",
    "        self.disc_X_optimizer = disc_X_optimizer\n",
    "        self.disc_Y_optimizer = disc_Y_optimizer\n",
    "        self.generator_loss_fn = gen_loss_fn\n",
    "        self.discriminator_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = keras.losses.MeanAbsoluteError()\n",
    "        self.identity_loss_fn = keras.losses.MeanAbsoluteError()\n",
    "        \n",
    "    def train_step(self, batch_data):\n",
    "        # x is dataA and y is dataB\n",
    "        real_x, real_y = batch_data\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # B to fake A\n",
    "            fake_y = self.gen_G(real_x, training=True)\n",
    "            # A to fake B -> y2x\n",
    "            fake_x = self.gen_F(real_y, training=True)\n",
    "\n",
    "            # Cycle (A to fake B to fake A): x -> y -> x\n",
    "            cycled_x = self.gen_F(fake_y, training=True)\n",
    "            # Cycle (B to fake A to fake B) y -> x -> y\n",
    "            cycled_y = self.gen_G(fake_x, training=True)\n",
    "\n",
    "            # Identity mapping\n",
    "            same_x = self.gen_F(real_x, training=True)\n",
    "            same_y = self.gen_G(real_y, training=True)\n",
    "\n",
    "            # Discriminator output\n",
    "            disc_real_x = self.disc_X(real_x, training=True)\n",
    "            disc_fake_x = self.disc_X(fake_x, training=True)\n",
    "\n",
    "            disc_real_y = self.disc_Y(real_y, training=True)\n",
    "            disc_fake_y = self.disc_Y(fake_y, training=True)\n",
    "\n",
    "            # Generator adverserial loss\n",
    "            gen_G_loss = self.generator_loss_fn(disc_fake_y)\n",
    "            gen_F_loss = self.generator_loss_fn(disc_fake_x)\n",
    "\n",
    "            # Generator cycle loss\n",
    "            cycle_loss_G = self.cycle_loss_fn(real_y, cycled_y) * (self.lambda_cycle/2)\n",
    "            cycle_loss_F = self.cycle_loss_fn(real_x, cycled_x) * (self.lambda_cycle/2)\n",
    "\n",
    "            # Generator identity loss\n",
    "            id_loss_G = (\n",
    "                self.identity_loss_fn(real_y, same_y)\n",
    "                * self.lambda_cycle\n",
    "                * self.lambda_identity\n",
    "            )\n",
    "            id_loss_F = (\n",
    "                self.identity_loss_fn(real_x, same_x)\n",
    "                * self.lambda_cycle\n",
    "                * self.lambda_identity\n",
    "            )\n",
    "\n",
    "            # Total generator loss\n",
    "            total_loss_G = gen_G_loss + id_loss_G #+ cycle_loss_G\n",
    "            total_loss_F = gen_F_loss + id_loss_F #+ cycle_loss_F \n",
    "\n",
    "            # Discriminator loss\n",
    "            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)\n",
    "            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)\n",
    "\n",
    "        # Get the gradients for the generators\n",
    "        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)\n",
    "        grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)\n",
    "\n",
    "        # Get the gradients for the discriminators\n",
    "        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)\n",
    "        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)\n",
    "\n",
    "        # Update the weights of the generators\n",
    "        self.gen_G_optimizer.apply_gradients(\n",
    "            zip(grads_G, self.gen_G.trainable_variables)\n",
    "        )\n",
    "        self.gen_F_optimizer.apply_gradients(\n",
    "            zip(grads_F, self.gen_F.trainable_variables)\n",
    "        )\n",
    "\n",
    "        # Update the weights of the discriminators\n",
    "        self.disc_X_optimizer.apply_gradients(\n",
    "            zip(disc_X_grads, self.disc_X.trainable_variables)\n",
    "        )\n",
    "        self.disc_Y_optimizer.apply_gradients(\n",
    "            zip(disc_Y_grads, self.disc_Y.trainable_variables)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"G_loss\": total_loss_G,\n",
    "            \"F_loss\": total_loss_F,\n",
    "            \"D_X_loss\": disc_X_loss,\n",
    "            \"D_Y_loss\": disc_Y_loss,\n",
    "        }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Callback to save the model periodically\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    \"\"\"A callback to generate and save images after each epoch\"\"\"\n",
    "\n",
    "    def __init__(self, num_img=4):\n",
    "        self.num_img = num_img\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs= None):\n",
    "        if (epoch % 10 == 0):\n",
    "            save_model(self.model, 'cyclegan_model/CycleGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions for the generators and discriminators \n",
    "\n",
    "# Loss function for evaluating adversarial loss\n",
    "adv_loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "# Define the loss function for the generators\n",
    "def generator_loss_fn(fake):\n",
    "    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n",
    "    return fake_loss\n",
    "\n",
    "\n",
    "# Define the loss function for the discriminators\n",
    "def discriminator_loss_fn(real, fake):\n",
    "    real_loss = adv_loss_fn(tf.ones_like(real), real)\n",
    "    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n",
    "    return (real_loss + fake_loss) * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "plotter = GANMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load or create a new CycleGAN model. Leave path blank if creating a new model. \n",
    "def load_model(path = None):\n",
    "    \n",
    "    if path == None:\n",
    "        # Create the generators\n",
    "        gen_G = get_resnet_generator(name=\"generator_G\")\n",
    "        gen_F = get_resnet_generator(name=\"generator_F\")\n",
    "\n",
    "        # Create the discriminators\n",
    "        disc_X = get_discriminator(name=\"discriminator_X\")\n",
    "        disc_Y = get_discriminator(name=\"discriminator_Y\")\n",
    "    else: \n",
    "        # Load the generators\n",
    "        genF = keras.models.load_model(path + '/gen_F')\n",
    "        genG = keras.models.load_model(path + '/gen_G')\n",
    "        \n",
    "        #Load the discriminators\n",
    "        discY = keras.models.load_model(path + '/disc_Y')\n",
    "        discX = keras.models.load_model(path + '/disc_X')\n",
    "        \n",
    "    \n",
    "    cycleGan_model = CycleGan(\n",
    "        generator_G=genG, generator_F=genF, discriminator_X=discX, discriminator_Y=discY\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    cycleGan_model.compile(\n",
    "        gen_G_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "        gen_F_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "        disc_X_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "        disc_Y_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n",
    "        gen_loss_fn=generator_loss_fn,\n",
    "        disc_loss_fn=discriminator_loss_fn,\n",
    "    )\n",
    "    return cycleGan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cycle_gan_model = load_model('cyclegan_model/CycleGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "history = cycle_gan_model.fit(\n",
    "    tf.data.Dataset.zip((trainB_data.repeat(1000), trainA_data.repeat(1000))),\n",
    "    epochs=401,\n",
    "    steps_per_epoch = 300,\n",
    "    callbacks=[plotter]#, model_checkpoint_callback]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history.history['G_loss']\n",
    "plt.plot(history.history['G_loss'])\n",
    "plt.plot(history.history['F_loss'])\n",
    "plt.plot(history.history['D_X_loss'])\n",
    "plt.plot(history.history['D_Y_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['G_loss', 'F_loss', 'D_X_loss', 'D_Y_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(cycle_gan_model, 'cyclegan_model/CycleGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "## Generate images using one of the two generators\n",
    "generator: generator to be used to produce images. \n",
    "test_set: a dataset object to be used by the generators to produce fake images\n",
    "image_list: an empty array of the images shape to store the predictions. \n",
    "\n",
    "'''\n",
    "def gen_function(generator, test_set, image_list):\n",
    "    if (generator == 'gen_G'): #To Fake A\n",
    "            for i, img in enumerate(test_set):\n",
    "                prediction = cycle_gan_model.gen_G(img, training=False)[0].numpy()\n",
    "                prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "                image_list[i, :, :, :] = prediction\n",
    "                \n",
    "            \n",
    "    elif (generator == 'gen_F'): #To Fake B\n",
    "            for i, img in enumerate(test_set):\n",
    "                prediction = cycle_gan_model.gen_F(img, training=False)[0].numpy()\n",
    "                prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n",
    "                image_list[i, :, :, :] = prediction\n",
    "                \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "## Generate images and compute the L1 distance\n",
    "dataset: a dataset object to be used by the generators to produce fake images\n",
    "images: numpy array of images to be used for the L1 distances \n",
    "'''\n",
    "def generate_image(dataset, images):\n",
    "    A_generated = gen_function('gen_G', dataset, np.zeros(images.shape))\n",
    "    B_generated = gen_function('gen_F', dataset, np.zeros(images.shape))\n",
    "    \n",
    "    A_distance = distance_array(A_generated, images, 'L1')\n",
    "    B_distance = distance_array(B_generated, images, 'L1')\n",
    "    \n",
    "    return A_generated, B_generated, A_distance, B_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake images and compute the L1 distances for the test data\n",
    "BA_test, BB_test, BA_test_dist, BB_test_dist = generate_image(testB_data, dataB2)\n",
    "AA_test, AB_test, AA_test_dist, AB_test_dist = generate_image(testA_data, dataA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake images and compute the L1 distances for the train data\n",
    "BA_train, BB_train, BA_train_dist, BB_train_dist = generate_image(trainB_data2, dataB1)\n",
    "AA_train, AB_train, AA_train_dist, AB_train_dist = generate_image(trainA_data2, dataA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the L1 distances using the distance to \n",
    "plt.scatter(BB_test_dist, BA_test_dist, c= \"blue\", label = \"Test B Images\", alpha = .100)\n",
    "plt.scatter(AB_test_dist, AA_test_dist, c= \"red\", label = \"Test A Images\", alpha = .10)\n",
    "\n",
    "\n",
    "plt.xlabel('L1 Distance To Negative Class', fontname='Times', fontsize = 10)\n",
    "plt.ylabel('L1 Distance To Positive Class', fontname='Times', fontsize = 10)\n",
    "plt.title(\"L1 Distance to Class\", fontname = 'Times', fontsize = 10)\n",
    "\n",
    "\n",
    "plt.xlim(0, .8*100000000) \n",
    "plt.ylim(0, .8*100000000)\n",
    "bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.8)\n",
    "plt.text(1e7, 1e7, \"3\", ha=\"center\", va=\"center\", size=10,\n",
    "        bbox=bbox_props)\n",
    "\n",
    "bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.8)\n",
    "plt.text(4e7, 1e7, \"2\", ha=\"center\", va=\"center\", size=10,\n",
    "        bbox=bbox_props)\n",
    "\n",
    "bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", alpha=0.9)\n",
    "plt.text(1e7, 4e7, \"1\", ha=\"center\", va=\"center\", size=10,\n",
    "        bbox=bbox_props)\n",
    "plt.legend()\n",
    "#plt.savefig('test_l1.pdf', bbox_inches = 'tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "B_distance: L1 distance in the B direction\n",
    "A_distance: L1 distance in A direction, computed from difference of the produced images from the original images. \n",
    "'''\n",
    "def translation_ratio(B_distance, A_distance):\n",
    "    TR = np.zeros(B_distance.shape[0])\n",
    "    for i in range(0, TR.shape[0]):\n",
    "        TR[i] = B_distance[i]/(B_distance[i]+A_distance[i])\n",
    "    return TR\n",
    "\n",
    "''' \n",
    "i: image index\n",
    "original: the original dataset\n",
    "cycled: the cycled dataset in either class direction (A or B)\n",
    "'''\n",
    "def metrics_scores(i, original, cycled):\n",
    "    l2dist = np.linalg.norm((cycled[i]/.255).ravel() - (original[i]/.255).ravel(), ord =2)\n",
    "    l1dist = np.linalg.norm((cycled[i]/.255).ravel() - (original[i]/.255).ravel(), ord =1)\n",
    "    ssim_val = ssim(original[i]/255., cycled[i]/255., multichannel = True)\n",
    "    return ssim_val, l1dist, l2dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "## Compute the translation ratio for the images. \n",
    "The negative class (B), should be inputed first and the positive class distance (A) should be used second. \n",
    "'''\n",
    "TR_A = translation_ratio(AB_test_dist, AA_test_dist)\n",
    "TR_B = translation_ratio(BB_test_dist, BA_test_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the translation ratio\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.hist(TR_B, bins = 30, alpha = .7, label = \"Test Benign Images\", color = 'blue')\n",
    "plt.hist(TR_A, bins = 30, alpha = .7, label = \"Test Malignant Images\", color = 'red')\n",
    "\n",
    "plt.ylabel(\"Count\", fontname='Times', fontsize = 10)\n",
    "plt.xlabel(\"Translation Ratio\", fontname='Times', fontsize = 10)\n",
    "plt.title(\"L1 Translation Ratios\", fontname='Times', fontsize = 10)\n",
    "plt.legend()\n",
    "plt.show\n",
    "#plt.savefig('test_tr.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "## Show a panel of images\n",
    "d1: original dataset (A or B)\n",
    "d2: distance to the negative class, B\n",
    "d3: distance to the positive class, A\n",
    "TR: translation ratio array for the original dataset (A or B)\n",
    "csv: csv of image names to be used to print the image's name if needed\n",
    "title: class of the input image\n",
    "prediction: an array of a CNN's predictions\n",
    "'''\n",
    "def show_panel(d1, d2, d3, TR, index, csv, title,  prediction = None):\n",
    "    \n",
    "    B_ssim, B_l1, B_l2 = metrics_scores(index, d1, d2)\n",
    "    A_ssim, A_l1, A_l2 = metrics_scores(index, d1, d3)\n",
    "\n",
    "   \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(figsize=(15, 10), ncols=3, nrows=1)\n",
    "    pos1 = ax1.imshow(d1[index,:,:,:]/255.)\n",
    "    ax1.set_title('Input\\n'+ title + ' Image', fontsize = 14)\n",
    "    ax1.text(0, 310, 'Translation Ratio L1: ' +  \"{:.4f}\".format(TR[index]), fontsize=14)\n",
    "    if prediction != None:\n",
    "        ax1.text(0, 330, \"CNN Prediction: \" + str(prediction[index]), fontsize=14)\n",
    "    \n",
    "    pos2 = ax2.imshow(d2[index,:,:,:]/255.)\n",
    "    #ax2.text(0, -70, \"Image: \" +str(csv[index]), fontsize=14)\n",
    "    ax2.set_title('Produced\\nBenign Image ', fontsize = 14)\n",
    "    ax2.text(0, 300, 'L1 Distance: ' + \"{:,.0f}\".format(B_l1), fontsize=14)\n",
    "    ax2.text(0, 320, 'L2 Distance: ' + \"{:,.0f}\".format(B_l2), fontsize=14)\n",
    "    ax2.text(0, 340, 'SSIM: ' + \"{:.4f}\".format(B_ssim), fontsize=14)\n",
    "\n",
    "\n",
    "    \n",
    "    pos3 = ax3.imshow(d3[index,:,:,:]/255.)\n",
    "    ax3.set_title('Produced\\n Malignant Image', fontsize = 14)\n",
    "    ax3.text(0, 300, 'L1 Distance: ' + \"{:,.0f}\".format(A_l1), fontsize=14)\n",
    "    ax3.text(0, 320, 'L2 Distance: ' + \"{:,.0f}\".format(A_l2), fontsize=14)\n",
    "    ax3.text(0, 340, 'SSIM: ' + \"{:.4f}\".format(A_ssim), fontsize=14)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the image index and then show the images\n",
    "copyA = test_A.reset_index()\n",
    "copyB = test_B.reset_index()\n",
    "show_panel(dataB2,BB_test, BA_test, TR_B, i, copyB['image_dir'], \"Benign\")\n",
    "show_panel(dataA2, AB_test, AA_test, TR_A, i, copyA['image_dir'], \"Malignant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a hexbin plot of the data. Use for larger image samples. \n",
    "\n",
    "x1 = BB_train_dist\n",
    "y1 = BA_train_dist\n",
    "\n",
    "x2 = AB_train_dist\n",
    "y2 = AA_train_dist\n",
    "\n",
    "# Define hexbin grid extent\n",
    "xmin = min(*x1, *x2)\n",
    "xmax = max(*x1, *x2)\n",
    "ymin = min(*y1, *y2)\n",
    "ymax = max(*y1, *y2)\n",
    "ext = (xmin, xmax, ymin, ymax)\n",
    "\n",
    "# Draw figure with colorbars\n",
    "plt.figure(figsize=(10, 6))\n",
    "hist1 = plt.hexbin(x1, y1, gridsize=30, cmap='Blues', mincnt=1, alpha=0.3, extent=ext)\n",
    "hist2 = plt.hexbin(x2, y2, gridsize=30, cmap='Reds', mincnt=1, alpha=.5, extent=ext)\n",
    "\n",
    "clb2 = plt.colorbar(hist2, orientation='vertical')\n",
    "clb1 = plt.colorbar(hist1, orientation='vertical')\n",
    "\n",
    "# Set titles \n",
    "clb1.ax.set_title('Benign Test Images',fontsize=10)\n",
    "clb2.ax.set_title('Malignant Test Images',fontsize=10)\n",
    "plt.title(\"L1 Distances\")\n",
    "plt.xlabel(\"L1 Distance to Benign\")\n",
    "plt.ylabel(\"L1 Distance to Malignant\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the distances to each class for the SVM \n",
    "def normalized_data(BB, BA, AB, AA):\n",
    "    stacked_B = np.stack((BB, BA), axis = 1)\n",
    "    stacked_A = np.stack((AB, AA), axis = 1)\n",
    "    \n",
    "    target_B = np.zeros((stacked_B.shape[0]))\n",
    "    target_A = np.ones((stacked_A.shape[0]))\n",
    "    \n",
    "    stacked_distances = np.vstack((stacked_B, stacked_A))\n",
    "    stacked_targets = np.concatenate((target_B, target_A))\n",
    "    \n",
    "    distance_mean = np.mean(stacked_distances)\n",
    "    distance_sd = np.std(stacked_distances)\n",
    "    mean_zero = (stacked_distances-distance_mean)/distance_sd\n",
    "    \n",
    "    X = mean_zero[:, :2]\n",
    "    y = stacked_targets\n",
    "    return  X, y\n",
    "\n",
    "X, y = normalized_data(BB_test_dist, BA_test_dist, AB_test_dist, AA_test_dist)\n",
    "X_train, y_train = normalized_data(BB_train_dist, BA_train_dist, AB_train_dist, AA_train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train an SVM with a weight, then use the trained model to predict on the test set\n",
    "def weighted_values(weight,X, y, predict_X):\n",
    "    svm_model= svm.SVC(kernel=\"linear\", class_weight= {1:weight}, probability = True, random_state = 316)\n",
    "    svm_model.fit(X, y)\n",
    "    return svm_model.predict_proba(predict_X)\n",
    "\n",
    "\n",
    "predicted_values_train = weighted_values(3, X_train, y_train, X_train)[:,1]\n",
    "predicted_values = weighted_values(3, X_train, y_train, X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve and computer the true and false positive rate\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, thresholds = sklearn.metrics.roc_curve(labels, predictions)\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]', fontsize = 10)\n",
    "    plt.ylabel('True positives [%]', fontsize = 10)\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    return fp, tp, thresholds\n",
    "\n",
    "def best_threshold(FPR, TPR, THRESHOLDS):\n",
    "    J = TPR - FPR\n",
    "    ix = argmax(J)\n",
    "    best_thresh = THRESHOLDS[ix]\n",
    "    print('Best SVM Threshold=%f' % (best_thresh))\n",
    "    \n",
    "plt.figure(figsize=(3,3))\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "FPR_train, TPR_train, THRESHOLDS = plot_roc(\"SVM Model Train\", y_train, predicted_values_train, color=colors[2])\n",
    "FPR_test, TPR_test, THRESHOLDS = plot_roc(\"SVM Model Test\", y, predicted_values, color=colors[1])\n",
    "\n",
    "\n",
    "# Add the AUC value to the graph. \n",
    "train_ROC = metrics.auc(FPR_train, TPR_train)\n",
    "test_ROC = metrics.auc(FPR_test, TPR_test)\n",
    "plt.text(35, 45, 'Train AUC: '+ \"{:.4f}\".format(train_ROC) + '\\nTest AUC: ' + \"{:.4f}\".format(test_ROC), size = 10, bbox={\n",
    "        'facecolor': 'white', 'alpha': 0.7, 'pad': 5})\n",
    "\n",
    "plt.legend(loc='lower right', fontsize = 10)\n",
    "plt.title(\"ROC Curve\", fontsize = 10)\n",
    "#plt.savefig('test_roc.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in a trained CNN model \n",
    "load_model_Full= tf.keras.models.load_model('models/cnn_melanoma_no_weights_7.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the loaded in model with additional metrics for evaluation. \n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "#       tf.keras.metrics.SpecificityAtSensitivity(.82)\n",
    "]\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 1e-5 )#1e-5)\n",
    "load_model_Full.compile(loss='binary_crossentropy', metrics=METRICS,optimizer=opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for evaluating and predicting images using the traditional CNN\n",
    "def model_evaluate(image_array, ground_truth, model):\n",
    "    tensor_predictions = tf.convert_to_tensor(image_array/255.)\n",
    "    tensor_truth = tf.convert_to_tensor(ground_truth)\n",
    "    model.evaluate(tensor_predictions, tensor_truth, batch_size = 1)\n",
    "    \n",
    "def model_predict(image_array, model):\n",
    "    tensor_predictions = tf.convert_to_tensor(image_array/255.)\n",
    "    CNN_model_predictions = model.predict(tensor_predictions)\n",
    "    return CNN_model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the same dataset to make predictions with the CNN. \n",
    "'''Use the predictions to evaluate missed images and plot the ROC curve against the CycleGAN'''\n",
    "full_test = np.vstack((dataB2, dataA2))\n",
    "test_ground_truth = np.concatenate((test_B.target.to_numpy(), test_A.target.to_numpy()), axis=None)\n",
    "test_ground_truth = np.concatenate((train_B.target.to_numpy(), train_A.target.to_numpy()), axis=None)\n",
    "full_train = np.vstack((dataB1, dataA1))\n",
    "\n",
    "\n",
    "CNN_predict = model_predict(full_test,load_CNN_full)\n",
    "CNN_predict_train = model_predict(full_train,load_CNN_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
